{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOK8eQ1nDxGeoYbTYA0uqE4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/NLP-Projects/blob/main/SentimentAnalysis-Pretrained-Word2Vec-Weights/sentiment_analysis_word2vec_embd_weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "XK_pIbYNdkID"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyO73WhfdZVf",
        "outputId": "c76d4f67-42de-4e99-f0f7-1085c1296c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gensim.downloader as api\n",
        "import pandas as pd\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense, Dropout"
      ],
      "metadata": {
        "id": "rOqG0xaldmnl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download & Load Dataset"
      ],
      "metadata": {
        "id": "FBEnft9LeIX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading Dataset...\")\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip\"\n",
        "r = requests.get(url)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n",
        "with z.open('sentiment labelled sentences/imdb_labelled.txt') as f:\n",
        "    # Read as CSV (tab separated)\n",
        "    df = pd.read_csv(f, sep='\\t', names=['sentence', 'label'], quoting=3)\n",
        "print(\"Dataset Downloaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmTr6kCceCLI",
        "outputId": "071f53bb-115a-4eee-c6b6-47a432747325"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Dataset...\n",
            "Dataset Downloaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display data samples\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(\"Sample Positive Review:\")\n",
        "print(df[df['label'] == 1].iloc[0]['sentence'])\n",
        "print(\"Sample Negative Review:\")\n",
        "print(df[df['label'] == 0].iloc[0]['sentence'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lHKZRB8eHkW",
        "outputId": "f216c4a5-7b13-4d53-e9c8-a9f505d800c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (1000, 2)\n",
            "Sample Positive Review:\n",
            "The best scene in the movie was when Gerardo is trying to find a song that keeps running through his head.  \n",
            "Sample Negative Review:\n",
            "A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = df['sentence'].values\n",
        "labels = df['label'].values"
      ],
      "metadata": {
        "id": "pDQhQTijeHhi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "K9Rn5oGge9z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization & Padding\n",
        "print(\"Preprocessing....\")\n",
        "MAX_VOCAB_SIZE = 5000\n",
        "MAX_SEQUENCE_LENGTH = 50\n",
        "EMBEDDING_DIM = 300\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "# convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "# Padding\n",
        "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "# Word Index\n",
        "# dict mapping words to integer\n",
        "word_index = tokenizer.word_index\n",
        "print(f\"Found {len(word_index)} unique tokens.\")\n",
        "print(f\"Data shape after padding: {padded_sequences.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnU1MmHheHev",
        "outputId": "dd26d604-e29c-4472-b2cc-16ee002ffc0e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing....\n",
            "Found 3134 unique tokens.\n",
            "Data shape after padding: (1000, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Pre-trained Word2Vec"
      ],
      "metadata": {
        "id": "qk7aEfr4foIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading Google Word2Vec...\")\n",
        "w2v_model = api.load(\"word2vec-google-news-300\")\n",
        "print(\"Word2Vec Loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqlZGGl4eHb6",
        "outputId": "2361b9c7-831e-473d-b6da-47e0dba04021"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Google Word2Vec...\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Word2Vec Loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Embedding Matrix"
      ],
      "metadata": {
        "id": "TaHdANxcf6E5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Injecting knowledge....\")\n",
        "num_words = min(MAX_VOCAB_SIZE, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_VOCAB_SIZE:\n",
        "        continue\n",
        "\n",
        "    if word in w2v_model:\n",
        "        embedding_matrix[i] = w2v_model[word]\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(f\"Converted {hits} words ({hits/(hits+misses)*100:.1f}%)\")\n",
        "print(f\"Missed {misses} words (will be learned from scratch or ignored)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT1xC97sfw6z",
        "outputId": "a72c2c4b-fccd-4e55-b37c-b588f4a0373b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injecting knowledge....\n",
            "Converted 2872 words (91.6%)\n",
            "Missed 262 words (will be learned from scratch or ignored)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build & Train Keras Model"
      ],
      "metadata": {
        "id": "pzZbmJqJgc0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Model....\")\n",
        "model = Sequential([\n",
        "    Embedding(\n",
        "        input_dim = num_words,\n",
        "        output_dim = EMBEDDING_DIM,\n",
        "        input_length = MAX_SEQUENCE_LENGTH,\n",
        "        weights = [embedding_matrix], # Injection Word2Vec Weights\n",
        "        trainable = False\n",
        "    ),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(24, activation=\"relu\"),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "s-KRd9U4gbWL",
        "outputId": "ec1a0b70-a35a-4cd3-aff5-8faccea6672c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │       \u001b[38;5;34m940,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">940,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m940,500\u001b[0m (3.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">940,500</span> (3.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m940,500\u001b[0m (3.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">940,500</span> (3.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "# We use a validation split to monitor performance\n",
        "history = model.fit(\n",
        "    padded_sequences,\n",
        "    labels,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "222Nl0aVgb28",
        "outputId": "0e8a2db8-ed3a-4e4f-d3b1-3c7deb7d60a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5137 - loss: 0.6933 - val_accuracy: 0.4700 - val_loss: 0.6910\n",
            "Epoch 2/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5526 - loss: 0.6889 - val_accuracy: 0.5200 - val_loss: 0.6870\n",
            "Epoch 3/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6189 - loss: 0.6817 - val_accuracy: 0.5450 - val_loss: 0.6808\n",
            "Epoch 4/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6327 - loss: 0.6791 - val_accuracy: 0.6850 - val_loss: 0.6714\n",
            "Epoch 5/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6633 - loss: 0.6679 - val_accuracy: 0.5800 - val_loss: 0.6682\n",
            "Epoch 6/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6966 - loss: 0.6538 - val_accuracy: 0.7300 - val_loss: 0.6545\n",
            "Epoch 7/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.6478 - val_accuracy: 0.7800 - val_loss: 0.6421\n",
            "Epoch 8/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7363 - loss: 0.6390 - val_accuracy: 0.7350 - val_loss: 0.6349\n",
            "Epoch 9/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.6262 - val_accuracy: 0.8400 - val_loss: 0.6156\n",
            "Epoch 10/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7354 - loss: 0.6281 - val_accuracy: 0.8050 - val_loss: 0.6063\n",
            "Epoch 11/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 0.6040 - val_accuracy: 0.8250 - val_loss: 0.5931\n",
            "Epoch 12/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7704 - loss: 0.5982 - val_accuracy: 0.8050 - val_loss: 0.5829\n",
            "Epoch 13/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7732 - loss: 0.5886 - val_accuracy: 0.8300 - val_loss: 0.5693\n",
            "Epoch 14/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.5913 - val_accuracy: 0.8450 - val_loss: 0.5568\n",
            "Epoch 15/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7765 - loss: 0.5667 - val_accuracy: 0.8450 - val_loss: 0.5417\n",
            "Epoch 16/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7925 - loss: 0.5488 - val_accuracy: 0.8500 - val_loss: 0.5314\n",
            "Epoch 17/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8389 - loss: 0.5269 - val_accuracy: 0.8400 - val_loss: 0.5163\n",
            "Epoch 18/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.5314 - val_accuracy: 0.8400 - val_loss: 0.5060\n",
            "Epoch 19/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7895 - loss: 0.5278 - val_accuracy: 0.8450 - val_loss: 0.4946\n",
            "Epoch 20/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.5106 - val_accuracy: 0.8500 - val_loss: 0.4875\n",
            "Epoch 21/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.5045 - val_accuracy: 0.8450 - val_loss: 0.4780\n",
            "Epoch 22/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7925 - loss: 0.5009 - val_accuracy: 0.8550 - val_loss: 0.4646\n",
            "Epoch 23/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8239 - loss: 0.4862 - val_accuracy: 0.8500 - val_loss: 0.4596\n",
            "Epoch 24/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8087 - loss: 0.4852 - val_accuracy: 0.8400 - val_loss: 0.4520\n",
            "Epoch 25/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8185 - loss: 0.4657 - val_accuracy: 0.8500 - val_loss: 0.4378\n",
            "Epoch 26/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.4572 - val_accuracy: 0.8600 - val_loss: 0.4365\n",
            "Epoch 27/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7999 - loss: 0.4663 - val_accuracy: 0.8650 - val_loss: 0.4273\n",
            "Epoch 28/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8331 - loss: 0.4530 - val_accuracy: 0.8600 - val_loss: 0.4233\n",
            "Epoch 29/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.4389 - val_accuracy: 0.8600 - val_loss: 0.4149\n",
            "Epoch 30/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8255 - loss: 0.4447 - val_accuracy: 0.8650 - val_loss: 0.4076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the Model"
      ],
      "metadata": {
        "id": "hHH_iBlmhcEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing....\")\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    # Process the new text exactly like training data\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    pad = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "    score = model.predict(pad, verbose=0)[0][0]\n",
        "\n",
        "    label = \"POSITIVE\" if score > 0.5 else \"NEGATIVE\"\n",
        "    print(f\"Text: '{text}'\")\n",
        "    print(f\"Sentiment: {label} ({score:.4f})\\n\")\n",
        "\n",
        "predict_sentiment(\"This movie was a masterpiece and I loved every second.\")\n",
        "predict_sentiment(\"Total waste of time, do not watch this garbage.\")\n",
        "predict_sentiment(\"It was okay, not great but not terrible.\") # Ambiguous\n",
        "predict_sentiment(\"The actor was good but the script was boring.\") # Mixed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEafH9wDgb0f",
        "outputId": "e4a0002d-7fc5-46a6-9709-fa8922add47b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing....\n",
            "Text: 'This movie was a masterpiece and I loved every second.'\n",
            "Sentiment: POSITIVE (0.8173)\n",
            "\n",
            "Text: 'Total waste of time, do not watch this garbage.'\n",
            "Sentiment: NEGATIVE (0.1525)\n",
            "\n",
            "Text: 'It was okay, not great but not terrible.'\n",
            "Sentiment: NEGATIVE (0.2765)\n",
            "\n",
            "Text: 'The actor was good but the script was boring.'\n",
            "Sentiment: NEGATIVE (0.2899)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PL8R0zIzgbx7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}