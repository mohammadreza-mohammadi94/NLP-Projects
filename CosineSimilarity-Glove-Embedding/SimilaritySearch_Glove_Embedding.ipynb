{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp30y6kqkgRVS1Oe8OfjE1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/NLP-Projects/blob/main/CosineSimilarity-Glove-Embedding/SimilaritySearch_Glove_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "XTN7SlYI7KcG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oNkLNk406OtN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download GloVe"
      ],
      "metadata": {
        "id": "arHBqSXy7Mb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_glove():\n",
        "    \"\"\"\n",
        "    Helper function to download the GloVe dataset if it doesn't exist locally.\n",
        "    Note: This file is ~822MB. It might take time.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(\"glove.6B.50d.txt\"):\n",
        "        print(\"Downloading GloVe...\")\n",
        "        url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "        r = requests.get(url)\n",
        "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "        z.extractall()\n",
        "        print(\"Download and extraction complete.\")\n",
        "    else:\n",
        "        print(\"GloVe file already exists.\")\n",
        "\n",
        "download_glove()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEJM0ipu7LYh",
        "outputId": "23424a5e-aee3-4553-dea5-8021abb3b962"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading GloVe...\n",
            "Download and extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Embedding Matrix"
      ],
      "metadata": {
        "id": "tHXyjJUq8CJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_manual(file_path):\n",
        "    \"\"\"\n",
        "    Parses the raw GloVe text file line by line and converts it into a Python dictionary.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the .txt file (e.g., 'glove.6B.50d.txt')\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are words (str) and values are vectors (numpy array).\n",
        "    \"\"\"\n",
        "    embeddings_dictionary = {}\n",
        "\n",
        "    print(f\"Reading file: {file_path}...\")\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                values = line.split()\n",
        "                word = values[0]\n",
        "\n",
        "                vector = np.asarray(values[1:], dtype='float32')\n",
        "\n",
        "                embeddings_dictionary[word] = vector\n",
        "\n",
        "        print(f\"Loading complete. Loaded {len(embeddings_dictionary)} words.\")\n",
        "        return embeddings_dictionary\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Creating a dummy dictionary for demonstration purposes.\")\n",
        "        return {\n",
        "            'cat': np.array([0.9, 0.1, 0.5, 0.2], dtype='float32'),\n",
        "            'dog': np.array([0.8, 0.2, 0.4, 0.3], dtype='float32'),\n",
        "            'car': np.array([0.1, 0.9, 0.0, 0.1], dtype='float32')\n",
        "        }"
      ],
      "metadata": {
        "id": "clmxIXEA7-IB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cosine Similarity"
      ],
      "metadata": {
        "id": "NCWqxs9-8L3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def manual_cosine_similarity(vec_a, vec_b):\n",
        "    \"\"\"\n",
        "    Calculates the cosine similarity between two vectors manually.\n",
        "    Formula: (A . B) / (||A|| * ||B||)\n",
        "    \"\"\"\n",
        "    dot_product = np.dot(vec_a, vec_b)\n",
        "    norm_a = np.linalg.norm(vec_a)\n",
        "    norm_b = np.linalg.norm(vec_b)\n",
        "\n",
        "    # calculate similarity\n",
        "    if norm_a == 0 or norm_b == 0:\n",
        "        return 0.0\n",
        "    similarity = dot_product / (norm_a * norm_b)\n",
        "    return similarity\n"
      ],
      "metadata": {
        "id": "RQAeE5A68LuD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution"
      ],
      "metadata": {
        "id": "f5AlIWdz8jmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the dataset\n",
        "glove_path = 'glove.6B.50d.txt'\n",
        "\n",
        "# Load embeddings\n",
        "embeddings = load_glove_manual(glove_path)\n",
        "\n",
        "# Test words\n",
        "word1 = 'cat'\n",
        "word2 = 'dog'\n",
        "word3 = 'car'\n",
        "\n",
        "# Check if words exist in our loaded dictionary\n",
        "if word1 in embeddings and word2 in embeddings and word3 in embeddings:\n",
        "\n",
        "    # Retrieve vectors\n",
        "    vec1 = embeddings[word1]\n",
        "    vec2 = embeddings[word2]\n",
        "    vec3 = embeddings[word3]\n",
        "\n",
        "    # Perform mathematical calculation\n",
        "    sim_cat_dog = manual_cosine_similarity(vec1, vec2)\n",
        "    sim_cat_car = manual_cosine_similarity(vec1, vec3)\n",
        "\n",
        "    print(f\"\\nResults:\")\n",
        "    print(f\">> Vector for '{word1}' (First 5 dims): {vec1[:5]}\")\n",
        "    print(f\">> Similarity between '{word1}' and '{word2}': {sim_cat_dog:.4f}\")\n",
        "    print(f\">> Similarity between '{word1}' and '{word3}': {sim_cat_car:.4f}\")\n",
        "\n",
        "    # Logical interpretation\n",
        "    if sim_cat_dog > sim_cat_car:\n",
        "        print(\"\\nLogic Check Passed: 'Cat' is mathematically closer to 'Dog' than to 'Car'.\")\n",
        "    else:\n",
        "        print(\"\\nLogic Check Failed.\")\n",
        "\n",
        "else:\n",
        "    print(\"One or more words were not found in the dictionary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeZ6cXKH8Lrm",
        "outputId": "b244f0eb-b5bb-4bdc-a53b-33dec0ac3d8c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading file: glove.6B.50d.txt...\n",
            "Loading complete. Loaded 400000 words.\n",
            "\n",
            "Results:\n",
            ">> Vector for 'cat' (First 5 dims): [ 0.45281  -0.50108  -0.53714  -0.015697  0.22191 ]\n",
            ">> Similarity between 'cat' and 'dog': 0.9218\n",
            ">> Similarity between 'cat' and 'car': 0.3638\n",
            "\n",
            "Logic Check Passed: 'Cat' is mathematically closer to 'Dog' than to 'Car'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nMizQjeT8LpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2l60ULy8LmN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}