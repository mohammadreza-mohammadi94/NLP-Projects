{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPpofLqG8xNHIyrnKFvZlM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/NLP-Projects/blob/main/Text%20Generation%20N-Grams%20-%20Probabilistic%20Model/Text_Generation_N_gram_Model_With_Chain_Rule_%7C_Markov_Assumptions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Libraries"
      ],
      "metadata": {
        "id": "wf407NUHLFH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import random\n",
        "import nltk\n",
        "from collections import defaultdict, Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"punkt_tab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRt8bXHELFAN",
        "outputId": "9808bb27-4c56-4c50-ccae-5f25d45bfb4e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "JygFlKlFLCgU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5wDGeu5hKuZF"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.gutenberg.org/files/2701/2701-0.txt\"\n",
        "# Get text\n",
        "text = requests.get(url).text\n",
        "\n",
        "# Filter mobydick corpus\n",
        "start = text.find(\"CHAPTER 1. Loomings.\")       # Start of text\n",
        "end = text.find(\"End of Project Gutenberg\")     # End of text\n",
        "text = text[start:end]                          # Full text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Cleaning"
      ],
      "metadata": {
        "id": "cO6x-VUYLey4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text).lower()\n",
        "tokens  = word_tokenize(text)\n",
        "tokens = ['<s>', '<s>'] + tokens + ['</s>']\n",
        "print(f\"Total words: {len(tokens)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cT44VM4LeWR",
        "outputId": "876806bd-4952-49fa-8045-1469833c1b45"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words: 212471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGyDtFaQLhQO",
        "outputId": "ab0cfab9-98ab-4df2-ef4f-762a1970e184"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " '<s>',\n",
              " 'chapter',\n",
              " 'loomings',\n",
              " 'chapter',\n",
              " 'the',\n",
              " 'carpetbag',\n",
              " 'chapter',\n",
              " 'the',\n",
              " 'spouterinn']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating `unigram`, `bigram`, `trigram`"
      ],
      "metadata": {
        "id": "eJ46-jffLjPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigrams = Counter(tokens)\n",
        "bigrams = Counter([(tokens[i], tokens[i+1]) for i in range(len(tokens) - 1)])\n",
        "trigrams = Counter([(tokens[i], tokens[i+1], tokens[i+2]) for i in range(len(tokens)-2)])\n",
        "print(f\"Bigram samples: \")\n",
        "for pair, count in bigrams.most_common(10):\n",
        "    print(f\"{pair} -> {count}\")\n",
        "\n",
        "print(\"\\n\\nTigrams samples: \")\n",
        "for triplet, count in bigrams.most_common(10):\n",
        "    print(f\"{triplet} -> {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYUzhtXzLn6z",
        "outputId": "c02069f0-6dc7-480e-cedd-12801bae096c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram samples: \n",
            "('of', 'the') -> 1887\n",
            "('in', 'the') -> 1179\n",
            "('to', 'the') -> 729\n",
            "('from', 'the') -> 441\n",
            "('of', 'his') -> 372\n",
            "('and', 'the') -> 370\n",
            "('on', 'the') -> 356\n",
            "('of', 'a') -> 333\n",
            "('at', 'the') -> 329\n",
            "('to', 'be') -> 327\n",
            "\n",
            "\n",
            "Tigrams samples: \n",
            "('of', 'the') -> 1887\n",
            "('in', 'the') -> 1179\n",
            "('to', 'the') -> 729\n",
            "('from', 'the') -> 441\n",
            "('of', 'his') -> 372\n",
            "('and', 'the') -> 370\n",
            "('on', 'the') -> 356\n",
            "('of', 'a') -> 333\n",
            "('at', 'the') -> 329\n",
            "('to', 'be') -> 327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating `Chain Rule Of Probability`"
      ],
      "metadata": {
        "id": "O1UoW9AXRc9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trigram_prob(w1, w2, w3):\n",
        "    bigram = (w1, w2)\n",
        "    trigram = (w1, w2, w3)\n",
        "    if bigrams[bigram] == 0:\n",
        "        return 0\n",
        "    return trigrams[trigram] / bigrams[bigram]"
      ],
      "metadata": {
        "id": "9ZO8eS4lP2dA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NvEVeQ-URxG4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Text"
      ],
      "metadata": {
        "id": "v5b7SM47R2P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sentence(start=('<s>', '<s>'), max_len=20):\n",
        "    w1, w2 = start\n",
        "    sentence = [w1, w2]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        candidates = [(w3, trigram_prob(w1, w2, w3))\n",
        "                      for (w1_, w2_, w3) in trigrams\n",
        "                      if w1_ == w1 and w2_ == w2]\n",
        "\n",
        "        if not candidates:\n",
        "            break\n",
        "\n",
        "        w3 = max(candidates, key=lambda x: x[1])[0]\n",
        "\n",
        "        if w3 == \"</s>\":\n",
        "            break\n",
        "\n",
        "        sentence.append(w3)\n",
        "        w1, w2 = w2, w3\n",
        "\n",
        "    return ' '.join(sentence[2:])\n",
        "\n",
        "# Test\n",
        "print(\"üìù Generated Sentence:\")\n",
        "print(generate_sentence())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6npgFFA2R10F",
        "outputId": "e2ed066a-c321-4dfc-c4b4-6f1e8b81f942"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Generated Sentence:\n",
            "chapter loomings chapter the pequod was as a general thing the mores the pity so if any strange face were\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NzXtzXu1R6_m"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}